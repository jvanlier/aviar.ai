{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision import *  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(\"~/labeled-sample\").expanduser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = load_learner(Path(\"~/models/\").expanduser(), \"2020-05-27_resnet18.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnd_jpeg(path, k):\n",
    "    return np.random.choice(list(path.glob(\"*.jpeg\")), size=k, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_home = rnd_jpeg(DATA_PATH / \"BirdHome\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = open_image(rnd_home[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.19 s ± 89.1 ms per loop (mean ± std. dev. of 3 runs, 3 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 3 -r 3\n",
    "\n",
    "pred = learn.predict(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WOW. That is slow. Did not expect that. And it's running on all 4 cores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, well. I guess running these images on full resolution has something to do with it.\n",
    "\n",
    "Unfortunately, I didn't get very good results training on lower resolutions. The bird is just too small. Maybe I should try again, though... at least to get a better understanding of performance at 0.9, .8, .7, .6, .5 of the original. What does that curve look like?\n",
    "\n",
    "Or, hmm, maybe I should try a MobileNet or something instead of ResNet 18 (although ResNet 18 isn't exactly large, and MobileNet has approx the same nr. or layers?)\n",
    "\n",
    "For now, I guess we can do 1 prediction every 15 - 20 seconds, which should *probably* give me enough of a heads-up if the bird is roaming when he shouldn't be, while giving the Pi some room to breathe as well.\n",
    "\n",
    "The gaps are probably too big to smoothen out noise over time though...\n",
    "\n",
    "Alternatively, I could try to run this on EC2. Maybe a t3.small would be sufficient. But that's still USD 200 a year (on demand pricing) which seems a bit steep for a hobby project :-)\n",
    "\n",
    "Or AWS Lambda ? This kernel uses ~ 400 MB memory. \n",
    "At the desired interval of 5 secs I'd be looking at roughly 0.5 M requests a month in the 512 MB bracket. If they take 10 secs as well, then back-of-the-envelope calculation still puts this at ~ 30 USD a month.\n",
    "\n",
    "Man, Deep Learning is expensive!\n",
    "\n",
    "Could also look into the [Coral USB TPU](https://coral.ai/products/accelerator/) (and switch back to TF). This supposedly works on a Pi. 100+ fps MobileNet v2, oh goody."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
